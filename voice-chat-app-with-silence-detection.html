<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Chat AI Assistant</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            background-color: #f9f9f9;
        }
        
        .app-container {
            display: flex;
            flex-direction: column;
            height: 100vh;
            max-height: 100vh;
        }

        .chat-container {
            flex-grow: 1;
            overflow-y: auto;
            padding: 20px;
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            margin-bottom: 20px;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px 15px;
            border-radius: 18px;
            max-width: 80%;
            line-height: 1.4;
        }

        .message.user {
            background-color: #e1f5fe;
            align-self: flex-end;
            margin-left: auto;
        }

        .message.assistant {
            background-color: #f0f0f0;
            align-self: flex-start;
        }

        .controls {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .button-row {
            display: flex;
            gap: 10px;
        }

        button {
            padding: 12px 15px;
            border: none;
            border-radius: 8px;
            background-color: #2962FF;
            color: white;
            font-size: 16px;
            cursor: pointer;
            transition: background-color 0.2s;
        }

        button:hover {
            background-color: #0039CB;
        }

        button:disabled {
            background-color: #BDBDBD;
            cursor: not-allowed;
        }

        .api-key-form {
            display: flex;
            flex-direction: column;
            gap: 10px;
            margin-bottom: 20px;
        }

        .api-key-form input {
            padding: 10px;
            font-size: 16px;
            border: 1px solid #ddd;
            border-radius: 8px;
        }

        .status {
            margin-top: 10px;
            font-style: italic;
            color: #757575;
        }

        .recording {
            color: #f44336;
            font-weight: bold;
        }
        
        .settings {
            margin-top: 10px;
            padding: 10px;
            background-color: #f5f5f5;
            border-radius: 8px;
        }
        
        .settings-title {
            font-weight: bold;
            margin-bottom: 8px;
        }
        
        .setting-item {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
        }
        
        .setting-item label {
            margin-right: 10px;
            min-width: 150px;
        }
        
        .setting-item input[type="number"] {
            width: 80px;
        }

        .setting-item input[type="range"] {
            width: 200px;
            margin: 0 10px;
        }

        .setting-item .value-display {
            min-width: 60px;
            text-align: right;
        }
    </style>
</head>
<body>
    <div class="app-container">
        <h1>Voice Chat AI Assistant</h1>
        
        <div class="api-key-form">
            <label for="api-key">OpenAI API Key:</label>
            <input type="password" id="api-key" placeholder="Enter your API key">
            <button id="save-key">Save API Key</button>
        </div>
        
        <div class="settings">
            <div class="settings-title">Conversation Settings</div>
            <div class="setting-item">
                <label for="silence-threshold">Silence Threshold (dB):</label>
                <input type="range" id="silence-threshold" value="-45" min="-60" max="-10" step="1">
                <span class="value-display" id="silence-threshold-value">-45</span>
            </div>
            <div class="setting-item">
                <label for="silence-duration">Silence Duration (ms):</label>
                <input type="range" id="silence-duration" value="1500" min="500" max="5000" step="100">
                <span class="value-display" id="silence-duration-value">1500</span>
            </div>
        </div>
        
        <div class="chat-container" id="chat-container"></div>
        
        <div class="controls">
            <div class="status" id="status">Ready</div>
            <div class="button-row">
                <button id="start-recording">Start Listening</button>
                <button id="stop-recording" disabled>Stop Listening</button>
                <button id="clear-chat">Clear Chat</button>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // DOM elements
            const chatContainer = document.getElementById('chat-container');
            const startRecordingButton = document.getElementById('start-recording');
            const stopRecordingButton = document.getElementById('stop-recording');
            const clearChatButton = document.getElementById('clear-chat');
            const statusElement = document.getElementById('status');
            const apiKeyInput = document.getElementById('api-key');
            const saveKeyButton = document.getElementById('save-key');
            const silenceThresholdInput = document.getElementById('silence-threshold');
            const silenceDurationInput = document.getElementById('silence-duration');
            
            // State variables
            let mediaRecorder;
            let audioChunks = [];
            let apiKey = localStorage.getItem('openai_api_key') || '';
            let audioContext;
            let analyser;
            let silenceStart = null;
            let isSilent = false;
            let silenceDetectionInterval;
            
            // Load settings from local storage
            const silenceThreshold = localStorage.getItem('silence_threshold') || -45;
            const silenceDuration = localStorage.getItem('silence_duration') || 1500;
            
            silenceThresholdInput.value = silenceThreshold;
            silenceDurationInput.value = silenceDuration;
            
            // Save settings when changed
            silenceThresholdInput.addEventListener('change', function() {
                localStorage.setItem('silence_threshold', this.value);
                statusElement.textContent = 'Settings saved';
                setTimeout(() => {
                    statusElement.textContent = 'Ready';
                }, 2000);
            });
            
            silenceDurationInput.addEventListener('change', function() {
                localStorage.setItem('silence_duration', this.value);
                statusElement.textContent = 'Settings saved';
                setTimeout(() => {
                    statusElement.textContent = 'Ready';
                }, 2000);
            });
            
            // Initialize
            if (apiKey) {
                apiKeyInput.value = '••••••••••••••••••••••••••';
                statusElement.textContent = 'API key loaded from storage';
            }
            
            // Save API key to local storage
            saveKeyButton.addEventListener('click', function() {
                const key = apiKeyInput.value.trim();
                if (key) {
                    localStorage.setItem('openai_api_key', key);
                    apiKey = key;
                    apiKeyInput.value = '••••••••••••••••••••••••••';
                    statusElement.textContent = 'API key saved successfully';
                    setTimeout(() => {
                        statusElement.textContent = 'Ready';
                    }, 2000);
                } else {
                    statusElement.textContent = 'Please enter a valid API key';
                }
            });
            
            // Update value displays for sliders
            silenceThresholdInput.addEventListener('input', function() {
                document.getElementById('silence-threshold-value').textContent = this.value;
            });

            silenceDurationInput.addEventListener('input', function() {
                document.getElementById('silence-duration-value').textContent = this.value;
            });
            
            // Add a message to the chat
            function addMessage(text, isUser) {
                const messageElement = document.createElement('div');
                messageElement.classList.add('message');
                messageElement.classList.add(isUser ? 'user' : 'assistant');
                messageElement.textContent = text;
                chatContainer.appendChild(messageElement);
                chatContainer.scrollTop = chatContainer.scrollHeight;
            }
            
            // Function to detect audio level and silence
            function detectSilence(stream) {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 512;
                analyser.smoothingTimeConstant = 0.4;
                source.connect(analyser);
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                silenceDetectionInterval = setInterval(() => {
                    analyser.getByteFrequencyData(dataArray);
                    
                    // Calculate volume level in dB
                    let sum = 0;
                    for(let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    
                    const average = sum / bufferLength;
                    // Convert to decibel scale (approximation)
                    const db = average === 0 ? -100 : 20 * Math.log10(average / 255);
                    
                    // Check if below threshold
                    const currentThreshold = parseFloat(silenceThresholdInput.value);
                    const currentSilenceDuration = parseInt(silenceDurationInput.value);
                    
                    if (db < currentThreshold) {
                        if (!isSilent) {
                            isSilent = true;
                            silenceStart = Date.now();
                        } else if (Date.now() - silenceStart > currentSilenceDuration) {
                            // Stop recording after silence duration
                            clearInterval(silenceDetectionInterval);
                            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                                stopRecording();
                            }
                        }
                    } else {
                        isSilent = false;
                        silenceStart = null;
                    }
                    
                    // Update status with volume level for debugging
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        statusElement.textContent = `Recording... Volume: ${db.toFixed(1)} dB`;
                    }
                }, 100);
            }
            
            // Start recording
            startRecordingButton.addEventListener('click', async function() {
                if (!apiKey) {
                    statusElement.textContent = 'Please enter an API key first';
                    return;
                }
                
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        } 
                    });
                    
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    
                    mediaRecorder.addEventListener('dataavailable', event => {
                        audioChunks.push(event.data);
                    });
                    
                    mediaRecorder.addEventListener('stop', async () => {
                        if (audioChunks.length === 0 || audioChunks[0].size === 0) {
                            statusElement.textContent = 'No audio detected, try again';
                            startRecordingButton.disabled = false;
                            stopRecordingButton.disabled = true;
                            statusElement.classList.remove('recording');
                            return;
                        }
                        
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        
                        try {
                            statusElement.textContent = 'Processing audio...';
                            const transcription = await transcribeAudio(audioBlob);
                            
                            if (transcription && transcription.trim()) {
                                addMessage(transcription, true);
                                statusElement.textContent = 'Getting AI response...';
                                const aiResponse = await getAIResponse(transcription);
                                addMessage(aiResponse, false);
                                speakResponse(aiResponse);
                            } else {
                                statusElement.textContent = 'No speech detected, try again';
                                startRecordingButton.disabled = false;
                                stopRecordingButton.disabled = true;
                            }
                        } catch (error) {
                            console.error('Error processing audio:', error);
                            statusElement.textContent = `Error: ${error.message}`;
                            startRecordingButton.disabled = false;
                            stopRecordingButton.disabled = true;
                        }
                    });
                    
                    mediaRecorder.start();
                    detectSilence(stream);
                    statusElement.textContent = 'Listening... Speak now';
                    statusElement.classList.add('recording');
                    startRecordingButton.disabled = true;
                    stopRecordingButton.disabled = false;
                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    statusElement.textContent = `Error: ${error.message}`;
                }
            });
            
            // Stop recording
            stopRecordingButton.addEventListener('click', function() {
                stopRecording();
            });
            
            function stopRecording() {
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    clearInterval(silenceDetectionInterval);
                    mediaRecorder.stop();
                    mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    startRecordingButton.disabled = false;
                    stopRecordingButton.disabled = true;
                    statusElement.classList.remove('recording');
                    statusElement.textContent = 'Processing...';
                    
                    if (audioContext) {
                        audioContext.close().then(() => {
                            audioContext = null;
                            analyser = null;
                        });
                    }
                }
            }
            
            // Clear chat
            clearChatButton.addEventListener('click', function() {
                chatContainer.innerHTML = '';
                statusElement.textContent = 'Chat cleared';
            });
            
            // Function to create safe headers (avoiding Unicode issues)
            function createSafeHeaders(authKey) {
                // Ensure the key is ASCII-only
                const safeKey = String(authKey).replace(/[^\x00-\x7F]/g, "");
                const headers = new Headers();
                headers.append('Authorization', 'Bearer ' + safeKey);
                return headers;
            }
            
            // Function to transcribe audio using OpenAI's Whisper API
            async function transcribeAudio(audioBlob) {
                const formData = new FormData();
                formData.append('file', audioBlob, 'recording.webm');
                formData.append('model', 'whisper-1');
                
                const headers = createSafeHeaders(apiKey);
                
                const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                    method: 'POST',
                    headers: headers,
                    body: formData
                });
                
                if (!response.ok) {
                    let errorMessage = 'Transcription failed';
                    try {
                        const errorData = await response.json();
                        errorMessage = errorData.error?.message || errorMessage;
                    } catch (e) {
                        // If JSON parsing fails, use the default message
                    }
                    throw new Error(errorMessage);
                }
                
                const data = await response.json();
                return data.text;
            }
            
            // Function to get AI response from OpenAI API
            async function getAIResponse(text) {
                const headers = createSafeHeaders(apiKey);
                headers.append('Content-Type', 'application/